{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing important modules\n",
    "\n",
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving key in api_key\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating llm object\n",
    "\n",
    "# llm = OpenAI(api_key = os.getenv('OPENAI_API_KEY'),temperature = 0.6)\n",
    "\n",
    "llm = OpenAI(temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of Australia is Canberra.\n"
     ]
    }
   ],
   "source": [
    "# checking llm object prediction \n",
    "\n",
    "text = \"please let me lknow capital of Australia\"\n",
    "\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving huggingface token\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACE_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Data Science\\Langchain\\First_Project\\myenv\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '0.19.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# using huggingface models with langchain\n",
    "\n",
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface = HuggingFaceHub(huggingfacehub_api_token=os.getenv('HUGGINGFACE_API_KEY'),repo_id = \"google/flan-t5-large\",model_kwargs={\"temperature\":0,\"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a data scientist with a masters degree in computer science. I am currently working for a company in the field of data science.\n"
     ]
    }
   ],
   "source": [
    "# prediction after using huggingface mode\n",
    "\n",
    "print(llm_huggingface.predict(\"write an resume cover letter for me, i am data scientist\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dear [Name],\n",
      "\n",
      "I am pleased to be applying for the [Position] role at [Company]. As a highly experienced data scientist, I am confident that my background and qualifications make me an ideal candidate for this role.\n",
      "\n",
      "I have a strong background in data science, with a masterâ€™s degree in mathematics and over five years of experience in data analysis, predictive modeling, and machine learning. I have a proven track record of success in developing and deploying data products that drive business value. My experience has also enabled me to develop strong problem-solving, analytical, and communication skills.\n",
      "\n",
      "I am confident that I can bring my expertise and enthusiasm to your organization. I am excited to have the opportunity to contribute to the success of [Company] and I look forward to discussing my qualifications in further detail.\n",
      "\n",
      "Thank you for your time and consideration.\n",
      "\n",
      "Sincerely,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "# prediction after using openAI model\n",
    "\n",
    "print(llm.predict(\"write an resume cover letter for me, i am data scientist\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates & LLM Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is capital of Russia?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# writing prompts using prompt template\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What is capital of {country}?\")\n",
    "prompt.format(country=\"Russia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Moscow is the capital of Russia.\n"
     ]
    }
   ],
   "source": [
    "# using chains for predicting output using openai model\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm,prompt=prompt)\n",
    "print(chain.run(\"Russia\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moscow\n"
     ]
    }
   ],
   "source": [
    "# using chains for predicting output using huggingface model\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm_huggingface,prompt=prompt)\n",
    "print(chain.run(\"Russia\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combining multiple chains  using simple sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing multiple prompts using prompt template\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "capital_template = PromptTemplate(input_variables=['country'],\n",
    "template=\"please tell me capital of {country}\")\n",
    "\n",
    "capital_chain = LLMChain(llm=llm,prompt=capital_template)\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'],\n",
    "template=\"let me know famous dishes of this {capital}\")\n",
    "\n",
    "famous_chain = LLMChain(llm=llm,prompt=famous_template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Butter Chicken\\n2. Chole Bhature\\n3. Aloo Paratha\\n4. Tandoori Chicken\\n5. Paneer Tikka\\n6. Dal Makhani\\n7. Kebabs\\n8. Biryani\\n9. Samosa\\n10. Chaat'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using SimpleSequentialChain for using multiple prompts in chain\n",
    "#  Note - it displays answer for last chain only\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "chain.run('India')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SEQUENTIAL CHAIN\n",
    "#### How to display all chain outputs ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing multiple prompts using prompt template\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "capital_template = PromptTemplate(input_variables=['country'],\n",
    "template=\"please tell me capital of {country}\")\n",
    "\n",
    "capital_chain = LLMChain(llm=llm,prompt=capital_template,output_key=\"capital\")\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'],\n",
    "template=\"let me know famous dishes of this {capital}\")\n",
    "\n",
    "famous_chain = LLMChain(llm=llm,prompt=famous_template,output_key=\"dishes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using SimpleSequentialChain for using multiple prompts in chain\n",
    "#  Note - it displays answer for last chain only\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(chains=[capital_chain,famous_chain],\n",
    "input_variables=[\"country\"],\n",
    "output_variables= [\"capital\",\"dishes\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'India',\n",
       " 'capital': '\\n\\nNew Delhi',\n",
       " 'dishes': ' is known for its diverse and delicious cuisine. Some of the most famous dishes of New Delhi include: \\n\\n1. Butter Chicken \\n2. Chole Bhature \\n3. Aloo Tikki \\n4. Kebabs \\n5. Dahi Bhalle \\n6. Chole Kulche \\n7. Paranthas \\n8. Jalebi \\n9. Chana Masala \\n10. Samosa'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({'country':'India'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Models with ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage,AIMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing chatllm object using chatOpenAI\n",
    "\n",
    "chatllm = ChatOpenAI(temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drafting system message and Humna message for chatmodel\n",
    "\n",
    "messages = [SystemMessage(content=\"Act as a Resturant chef\") ,\n",
    "            HumanMessage(content=\"Suggest me paneer dishes for my breakfast\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Certainly! Here are a few delicious paneer dishes that you can enjoy for breakfast:\\n\\n1. Paneer Paratha: A popular Indian breakfast dish, it consists of a stuffed flatbread made with paneer, spices, and herbs. Serve it with yogurt or pickle for a delightful meal.\\n\\n2. Paneer Bhurji: A scrambled paneer dish, made by sautÃ©ing crumbled paneer with onions, tomatoes, and spices. Enjoy it with toasted bread or as a filling for sandwiches.\\n\\n3. Paneer Poha: A variation of the traditional Indian flattened rice dish, this recipe includes paneer cubes, peas, and spices mixed with the flattened rice. It's a light and flavorful option for breakfast.\\n\\n4. Paneer and Vegetable Upma: Upma is a savory semolina porridge, and adding paneer and vegetables to it makes it more nutritious and delicious. It's a quick and easy breakfast option.\\n\\n5. Paneer Stuffed Dosa: Prepare a regular dosa batter and stuff it with a mixture of crumbled paneer, spices, and herbs. Serve it with coconut chutney or sambar for a fulfilling breakfast.\\n\\n6. Paneer Sandwich: Make a delicious sandwich with paneer, sliced vegetables, and your favorite spreads like mint chutney or mayonnaise. Grill it until crispy, and enjoy a tasty and filling breakfast.\\n\\nRemember, you can always customize these recipes by adding or removing ingredients according to your taste preferences. Enjoy your paneer breakfast dishes!\")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here are a few delicious paneer dishes that you can enjoy for breakfast:\\n\\n1. Paneer Paratha: A stuffed flatbread made with a filling of crumbled paneer, spices, and herbs. Serve it with yogurt or pickle for a delightful breakfast.\\n\\n2. Paneer Bhurji: Scrambled paneer cooked with onions, tomatoes, and spices. Enjoy it with roti or bread for a filling breakfast option.\\n\\n3. Paneer Sandwich: Grilled sandwich with paneer slices, along with cucumber, tomatoes, and a spread of mint chutney. It's a perfect grab-and-go breakfast option.\\n\\n4. Paneer Idli: Add crumbled paneer to your regular idli batter for a protein-packed twist. Serve with coconut chutney or sambar for a wholesome breakfast.\\n\\n5. Paneer Tacos: Sauteed paneer with bell peppers, onions, and spices, wrapped in a tortilla or taco shell. Top it with salsa, sour cream, and guacamole for a fusion breakfast treat.\\n\\n6. Paneer Stuffed Dosa: Prepare a dosa batter and stuff it with a mixture of crumbled paneer, onions, and spices. Serve with coconut chutney or sambar for a South Indian breakfast delight.\\n\\n7. Paneer Omelette: Beat eggs with crumbled paneer, onions, tomatoes, and spices. Cook it like a regular omelette and enjoy it with toast or paratha.\\n\\nRemember to adjust the spices and flavors according to your taste preferences. Enjoy your paneer-filled breakfast!\")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hues', 'shades', 'tints', 'pigments', 'tones']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a object, and you should generate 5 synonyms of that object in a comma separated list.\n",
    "ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "chain = chat_prompt | ChatOpenAI() | CommaSeparatedListOutputParser()\n",
    "\n",
    "chain.invoke({\"text\": \"colors\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
